{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG5aVXAnBQlV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vfMoOeQAtn6",
        "outputId": "a738ab6c-b807-40b6-fb4b-f7f321ed9313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 5385313.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 158282.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1289241.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9050132.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgTNp8UwCMJ9"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataset = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qTByUr2Hs_1"
      },
      "outputs": [],
      "source": [
        "class MNIST_NN(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.input_layer = nn.Linear(28*28, 64)\n",
        "      self.hidden_layer = nn.Linear(64, 64)\n",
        "      self.output_layer = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.input_layer(x))\n",
        "    x = F.relu(self.hidden_layer(x))\n",
        "    x = self.output_layer(x)\n",
        "    return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMgNSvA6QEMb",
        "outputId": "162404c3-fe50-4c99-ea3c-03bd62cb0acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/1875], Loss: 0.7480584383010864\n",
            "Epoch [1/5], Step [200/1875], Loss: 0.3035137951374054\n",
            "Epoch [1/5], Step [300/1875], Loss: 0.3697083294391632\n",
            "Epoch [1/5], Step [400/1875], Loss: 0.16306354105472565\n",
            "Epoch [1/5], Step [500/1875], Loss: 0.20854932069778442\n",
            "Epoch [1/5], Step [600/1875], Loss: 0.22569096088409424\n",
            "Epoch [1/5], Step [700/1875], Loss: 0.31162458658218384\n",
            "Epoch [1/5], Step [800/1875], Loss: 0.16837386786937714\n",
            "Epoch [1/5], Step [900/1875], Loss: 0.45358210802078247\n",
            "Epoch [1/5], Step [1000/1875], Loss: 0.483830064535141\n",
            "Epoch [1/5], Step [1100/1875], Loss: 0.08739211410284042\n",
            "Epoch [1/5], Step [1200/1875], Loss: 0.20223617553710938\n",
            "Epoch [1/5], Step [1300/1875], Loss: 0.09270298480987549\n",
            "Epoch [1/5], Step [1400/1875], Loss: 0.1623680144548416\n",
            "Epoch [1/5], Step [1500/1875], Loss: 0.031897272914648056\n",
            "Epoch [1/5], Step [1600/1875], Loss: 0.13131262362003326\n",
            "Epoch [1/5], Step [1700/1875], Loss: 0.14072059094905853\n",
            "Epoch [1/5], Step [1800/1875], Loss: 0.03335759416222572\n",
            "Epoch [2/5], Step [100/1875], Loss: 0.1736714392900467\n",
            "Epoch [2/5], Step [200/1875], Loss: 0.03178948536515236\n",
            "Epoch [2/5], Step [300/1875], Loss: 0.24878433346748352\n",
            "Epoch [2/5], Step [400/1875], Loss: 0.112054742872715\n",
            "Epoch [2/5], Step [500/1875], Loss: 0.502992570400238\n",
            "Epoch [2/5], Step [600/1875], Loss: 0.14221727848052979\n",
            "Epoch [2/5], Step [700/1875], Loss: 0.07421457767486572\n",
            "Epoch [2/5], Step [800/1875], Loss: 0.1800483912229538\n",
            "Epoch [2/5], Step [900/1875], Loss: 0.091352179646492\n",
            "Epoch [2/5], Step [1000/1875], Loss: 0.20106440782546997\n",
            "Epoch [2/5], Step [1100/1875], Loss: 0.2012064903974533\n",
            "Epoch [2/5], Step [1200/1875], Loss: 0.36682385206222534\n",
            "Epoch [2/5], Step [1300/1875], Loss: 0.03492287918925285\n",
            "Epoch [2/5], Step [1400/1875], Loss: 0.10489146411418915\n",
            "Epoch [2/5], Step [1500/1875], Loss: 0.19194620847702026\n",
            "Epoch [2/5], Step [1600/1875], Loss: 0.16800764203071594\n",
            "Epoch [2/5], Step [1700/1875], Loss: 0.2915545105934143\n",
            "Epoch [2/5], Step [1800/1875], Loss: 0.03521205484867096\n",
            "Epoch [3/5], Step [100/1875], Loss: 0.12834952771663666\n",
            "Epoch [3/5], Step [200/1875], Loss: 0.10745339840650558\n",
            "Epoch [3/5], Step [300/1875], Loss: 0.0962156429886818\n",
            "Epoch [3/5], Step [400/1875], Loss: 0.055472761392593384\n",
            "Epoch [3/5], Step [500/1875], Loss: 0.1705828458070755\n",
            "Epoch [3/5], Step [600/1875], Loss: 0.05494047701358795\n",
            "Epoch [3/5], Step [700/1875], Loss: 0.04102780297398567\n",
            "Epoch [3/5], Step [800/1875], Loss: 0.05923205986618996\n",
            "Epoch [3/5], Step [900/1875], Loss: 0.13840362429618835\n",
            "Epoch [3/5], Step [1000/1875], Loss: 0.11112711578607559\n",
            "Epoch [3/5], Step [1100/1875], Loss: 0.04307633638381958\n",
            "Epoch [3/5], Step [1200/1875], Loss: 0.41467586159706116\n",
            "Epoch [3/5], Step [1300/1875], Loss: 0.09671708196401596\n",
            "Epoch [3/5], Step [1400/1875], Loss: 0.0458233617246151\n",
            "Epoch [3/5], Step [1500/1875], Loss: 0.08560208231210709\n",
            "Epoch [3/5], Step [1600/1875], Loss: 0.04848358780145645\n",
            "Epoch [3/5], Step [1700/1875], Loss: 0.018887998536229134\n",
            "Epoch [3/5], Step [1800/1875], Loss: 0.11042299121618271\n",
            "Epoch [4/5], Step [100/1875], Loss: 0.04168729856610298\n",
            "Epoch [4/5], Step [200/1875], Loss: 0.05301379784941673\n",
            "Epoch [4/5], Step [300/1875], Loss: 0.1834055334329605\n",
            "Epoch [4/5], Step [400/1875], Loss: 0.010707724839448929\n",
            "Epoch [4/5], Step [500/1875], Loss: 0.1020372211933136\n",
            "Epoch [4/5], Step [600/1875], Loss: 0.15714889764785767\n",
            "Epoch [4/5], Step [700/1875], Loss: 0.01934541016817093\n",
            "Epoch [4/5], Step [800/1875], Loss: 0.21443043649196625\n",
            "Epoch [4/5], Step [900/1875], Loss: 0.08199413865804672\n",
            "Epoch [4/5], Step [1000/1875], Loss: 0.04784392565488815\n",
            "Epoch [4/5], Step [1100/1875], Loss: 0.007496831472963095\n",
            "Epoch [4/5], Step [1200/1875], Loss: 0.04989013820886612\n",
            "Epoch [4/5], Step [1300/1875], Loss: 0.2619278132915497\n",
            "Epoch [4/5], Step [1400/1875], Loss: 0.12155068665742874\n",
            "Epoch [4/5], Step [1500/1875], Loss: 0.12545615434646606\n",
            "Epoch [4/5], Step [1600/1875], Loss: 0.09738218039274216\n",
            "Epoch [4/5], Step [1700/1875], Loss: 0.04385727643966675\n",
            "Epoch [4/5], Step [1800/1875], Loss: 0.040812693536281586\n",
            "Epoch [5/5], Step [100/1875], Loss: 0.011426275596022606\n",
            "Epoch [5/5], Step [200/1875], Loss: 0.013009716756641865\n",
            "Epoch [5/5], Step [300/1875], Loss: 0.01566612534224987\n",
            "Epoch [5/5], Step [400/1875], Loss: 0.06306738406419754\n",
            "Epoch [5/5], Step [500/1875], Loss: 0.07403108477592468\n",
            "Epoch [5/5], Step [600/1875], Loss: 0.01742948219180107\n",
            "Epoch [5/5], Step [700/1875], Loss: 0.11128097027540207\n",
            "Epoch [5/5], Step [800/1875], Loss: 0.11595839262008667\n",
            "Epoch [5/5], Step [900/1875], Loss: 0.038856927305459976\n",
            "Epoch [5/5], Step [1000/1875], Loss: 0.07049720734357834\n",
            "Epoch [5/5], Step [1100/1875], Loss: 0.010012608021497726\n",
            "Epoch [5/5], Step [1200/1875], Loss: 0.16425389051437378\n",
            "Epoch [5/5], Step [1300/1875], Loss: 0.027091175317764282\n",
            "Epoch [5/5], Step [1400/1875], Loss: 0.009357938542962074\n",
            "Epoch [5/5], Step [1500/1875], Loss: 0.07283434271812439\n",
            "Epoch [5/5], Step [1600/1875], Loss: 0.06106378883123398\n",
            "Epoch [5/5], Step [1700/1875], Loss: 0.03747761622071266\n",
            "Epoch [5/5], Step [1800/1875], Loss: 0.07782629877328873\n"
          ]
        }
      ],
      "source": [
        "model = MNIST_NN()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 5\n",
        "NUM_BATCHES = len(train_dataset)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for i, batch in enumerate(train_dataset):\n",
        "    x, y = batch\n",
        "    model.zero_grad()\n",
        "    output = model(x.view(-1, 784))\n",
        "    loss = F.nll_loss(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "      print (f\"Epoch [{epoch+1}/{EPOCHS}], Step [{i+1}/{NUM_BATCHES}], Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92IgXSDyVZmP"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "        for batch in dataloader:\n",
        "            x, y = batch\n",
        "\n",
        "            # Check the size of the input and make sure it matches what we expect\n",
        "            if x.shape[1:] != (1, 28, 28):\n",
        "                raise RuntimeError(f\"Expected input of size [batch_size, 1, 28, 28], but got {x.shape}\")\n",
        "\n",
        "            # Flatten the input only if it's in the correct shape\n",
        "            x = x.view(-1, 784)\n",
        "\n",
        "            output = model(x)\n",
        "\n",
        "            # Get the predicted class by finding the index of the max log-probability\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            # Count correct predictions\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100  # Convert to percentage\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZdVoRXBiheh"
      },
      "outputs": [],
      "source": [
        "calculate_accuracy(model, test_dataset)\n",
        "torch.save(model.state_dict(),\"model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7-bHJRfinL6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
